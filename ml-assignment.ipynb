{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing important modules and setting up the project"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import f1_score\n\nfrom tensorflow.python import keras\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\n\nimport xgboost\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nimport tensorflow as tf\nfrom keras import backend as K\n\nfrom sklearn.model_selection import GridSearchCV\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reading the data from files"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/my-sample-data/train.csv')\ntest = pd.read_csv('../input/my-sample-data/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictor_cols = ['additional_fare', 'duration', 'meter_waiting', 'meter_waiting_fare', 'meter_waiting_till_pickup', 'fare']\ntrain_X = train[predictor_cols]\ntest_X = test[predictor_cols]\n\n#train_y.fillna(train_y.mean(), inplace=True)\ntrain.fillna(train_X.mean(), inplace=True)\ntest.fillna(test_X.mean(), inplace=True)\ntrain['num_label'] = False\ntrain['direct_distance'] = 0.0\ntest['direct_distance'] = 0.0\n\ntrain['pickup_time'] = pd.to_datetime(train['pickup_time'], errors='coerce')\ntest['pickup_time'] = pd.to_datetime(test['pickup_time'], errors='coerce')\n\ntrain['drop_time'] = pd.to_datetime(train['drop_time'], errors='coerce')\ntest['drop_time'] = pd.to_datetime(test['drop_time'], errors='coerce')\n\ntrain['pick_hour'] = train['pickup_time'].dt.hour\ntrain['drop_hour'] = train['drop_time'].dt.hour\n\ntest['pick_hour'] = test['pickup_time'].dt.hour\ntest['drop_hour'] = test['drop_time'].dt.hour\n\n\nfor index, row in train.iterrows():\n    lat1, lng1, lat2, lng2 = map(np.radians, (row['drop_lat'], row['drop_lon'], row['pick_lat'], row['pick_lon']))\n    lat = lat2 - lat1\n    lng = lng2 - lng1\n    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n    h = 2 * 6371 * np.arcsin(np.sqrt(d))\n    train.at[index,'direct_distance'] = 2 * 6371 * np.arcsin(np.sqrt(d))\n    #d = (((row['drop_lon'] - row['pick_lon'])**2)+((row['drop_lat'] - row['pick_lat'])**2))\n    #train.at[index,'direct_distance'] = 2 * 6371 * np.arcsin()\n    \nfor index, row in test.iterrows():\n    lat1, lng1, lat2, lng2 = map(np.radians, (row['drop_lat'], row['drop_lon'], row['pick_lat'], row['pick_lon']))\n    lat = lat2 - lat1\n    lng = lng2 - lng1\n    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n    h = 2 * 6371 * np.arcsin(np.sqrt(d))\n    test.at[index,'direct_distance'] = 2 * 6371 * np.arcsin(np.sqrt(d))\n\n\ntrain['fare_for_duration'] = (train['fare'] - train['meter_waiting_fare'])/train['duration']\n#train['fare_for_distance'] = (train['fare'] - train['meter_waiting_fare'])/train['direct_distance']\ntrain['fare_for_time'] = (train['fare'] - train['meter_waiting_fare'])/(train['duration']+train['meter_waiting_till_pickup'])\n#train['distance_for_time'] = train['direct_distance']/train['duration']\ntrain['meter_waiting_to_duration'] = train['meter_waiting']/train['duration']\ntrain['additional_fare_to_duration'] = train['additional_fare']/train['duration']\n#train['additional_fare_to_distance'] = train['additional_fare']/train['direct_distance']\ntrain['additional_fare_to_fare'] = train['additional_fare']/(train['fare']+train['additional_fare'])\ntrain['mtr_wating_fare_to_waiting_duration'] = train['meter_waiting_fare']/(train['meter_waiting']+train['meter_waiting_till_pickup'])\ntrain['additional_fare_to_full_time'] = train['additional_fare']/(train['meter_waiting']+train['meter_waiting_till_pickup']+train['duration'])\ntrain['full_waiting_fare_to_full_time'] = (train['meter_waiting_fare']+train['additional_fare'])/(train['meter_waiting']+train['meter_waiting_till_pickup']+train['duration'])\ntrain['net_fare_for_durtion'] = (train['fare'] - (train['additional_fare']+train['meter_waiting_fare']))/train['duration']\n\ntest['fare_for_duration'] = (test['fare'] - test['meter_waiting_fare'])/test['duration']\n#test['fare_for_distance'] = (test['fare'] - test['meter_waiting_fare'])/test['direct_distance']\ntest['fare_for_time'] = (test['fare'] - test['meter_waiting_fare'])/(test['duration']+test['meter_waiting_till_pickup'])\n#test['distance_for_time'] = test['direct_distance']/test['duration']\ntest['meter_waiting_to_duration'] = test['meter_waiting']/test['duration']\ntest['additional_fare_to_duration'] = test['additional_fare']/test['duration']\n#test['additional_fare_to_distance'] = test['additional_fare']/test['direct_distance']\ntest['additional_fare_to_fare'] = test['additional_fare']/(test['fare']+test['additional_fare'])\ntest['mtr_wating_fare_to_waiting_duration'] = test['meter_waiting_fare']/(test['meter_waiting']+test['meter_waiting_till_pickup'])\ntest['additional_fare_to_full_time'] = test['additional_fare']/(test['meter_waiting']+test['meter_waiting_till_pickup']+test['duration'])\ntest['full_waiting_fare_to_full_time'] = (test['meter_waiting_fare']+test['additional_fare'])/(test['meter_waiting']+test['meter_waiting_till_pickup']+test['duration'])\ntest['net_fare_for_durtion'] = (test['fare'] - (test['additional_fare']+test['meter_waiting_fare']))/test['duration']\n\ntrain.replace([np.inf, -np.inf], np.nan)\ntest.replace([np.inf, -np.inf], np.nan)\ntrain.fillna(train.mean(), inplace=True)\ntest.fillna(test.mean(), inplace=True)\n\ntrain['fare_for_duration'] = train['fare_for_duration'].astype(np.float32)\n#train['fare_for_distance'] = train['fare_for_distance'].astype(np.float32)\ntrain['fare_for_time'] = train['fare_for_time'].astype(np.float32)\n#train['distance_for_time'] = train['distance_for_time'].astype(np.float32)\ntrain['meter_waiting_to_duration'] = train['meter_waiting_to_duration'].astype(np.float32)\ntrain['additional_fare_to_duration'] = train['additional_fare_to_duration'].astype(np.float32)\n#train['additional_fare_to_distance'] = train['additional_fare_to_distance'].astype(np.float32)\ntrain['additional_fare_to_fare'] = train['additional_fare_to_fare'].astype(np.float32)\ntrain['mtr_wating_fare_to_waiting_duration'] = train['mtr_wating_fare_to_waiting_duration'].astype(np.float32)\ntrain['additional_fare_to_full_time'] = train['additional_fare_to_full_time'].astype(np.float32)\ntrain['full_waiting_fare_to_full_time'] = train['full_waiting_fare_to_full_time'].astype(np.float32)\ntrain['net_fare_for_durtion'] = train['net_fare_for_durtion'].astype(np.float32)\n\ntest['fare_for_duration'] = test['fare_for_duration'].astype(np.float32)\n#test['fare_for_distance'] = test['fare_for_distance'].astype(np.float32)\ntest['fare_for_time'] = test['fare_for_time'].astype(np.float32)\n#test['distance_for_time'] = test['distance_for_time'].astype(np.float32)\ntest['meter_waiting_to_duration'] = test['meter_waiting_to_duration'].astype(np.float32)\ntest['additional_fare_to_duration'] = test['additional_fare_to_duration'].astype(np.float32)\n#test['additional_fare_to_distance'] = test['additional_fare_to_distance'].astype(np.float32)\ntest['additional_fare_to_fare'] = test['additional_fare_to_fare'].astype(np.float32)\ntest['mtr_wating_fare_to_waiting_duration'] = test['mtr_wating_fare_to_waiting_duration'].astype(np.float32)\ntest['additional_fare_to_full_time'] = test['additional_fare_to_full_time'].astype(np.float32)\ntest['full_waiting_fare_to_full_time'] = test['full_waiting_fare_to_full_time'].astype(np.float32)\ntest['net_fare_for_durtion'] = test['net_fare_for_durtion'].astype(np.float32)\n\nfor index, row in train.iterrows():\n    if(row['label'] == \"correct\"):\n        train.at[index, 'num_label'] = 1\n    else:\n        train.at[index, 'num_label'] = 0\n\n\n#train_y = train['label']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 'fare_for_distance',\n# 'distance_for_time', 'additional_fare_to_distance', 'distance_for_time', 'only_fare_for_duration',\npredictor_cols = ['additional_fare', 'net_fare_for_durtion', 'full_waiting_fare_to_full_time', 'additional_fare_to_full_time', 'mtr_wating_fare_to_waiting_duration', 'fare_for_time', 'meter_waiting_to_duration', 'fare_for_duration', 'additional_fare_to_duration', 'additional_fare_to_fare', 'pick_hour', 'drop_hour', 'pick_lat', 'pick_lon', 'direct_distance', 'duration', 'meter_waiting', 'meter_waiting_fare', 'meter_waiting_till_pickup', 'fare']\ntrain_X_ = train[predictor_cols]\ntest_X = test[predictor_cols]\ntrain_X_.replace([np.inf, -np.inf], np.nan)\ntest_X.replace([np.inf, -np.inf], np.nan)\ntrain_X_.fillna(train_X_.mean(), inplace=True)\ntest_X.fillna(test_X.mean(), inplace=True)\n\ntrain_y_ = train.num_label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X, val_X, train_y, val_y = train_test_split(train_X_, train_y_, test_size = 0.2, train_size = 0.8, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, test_features, test_labels):\n    predictions = model.predict(test_features)\n    mse = mean_squared_error(test_labels, predictions)\n    mae = mean_absolute_error(test_labels, predictions)\n    rmse = np.sqrt(mse)\n    score=cross_val_score(model, test_features, test_labels, cv=10)\n    accuracy = accuracy_score(test_labels, predictions.round())\n    print('Model Performance')\n    print('Accuracy:%f'%accuracy)\n    print(\"Mean cross validation score:%f\"%score.mean())\n    print('Mean Squared Error : %.4f' % mse)\n    print('Root MSE : %.4f' % rmse)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random forest model"},{"metadata":{"trusted":true},"cell_type":"code","source":"my_random_forest_model = RandomForestRegressor(n_estimators=100, random_state = 0)\nmy_random_forest_model.fit(train_X, train_y)\n\nevaluate(my_random_forest_model, val_X, val_y)\n\npred_classes = my_random_forest_model.predict(val_X)\npredi = []\nfor x in range(len(pred_classes)):\n    predi.append(bool(pred_classes[x]))\n    \npred_classes = np.array(predi)\n\nf1 = f1_score(val_y, pred_classes)\nprint('F1 score: %f' % f1)\n# Multiply by -1 since sklearn calculates *negative* MAE\n#scores = cross_val_score(my_pipeline, X, y, cv=5, scoring='neg_mean_absolute_error')\n#scores = cross_val_score(my_random_forest_model, train_X, train_y.round(), scoring='f1')\n#print(\"MAE scores:\\n\", scores)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Decision tree model"},{"metadata":{"trusted":true},"cell_type":"code","source":"my_decision_tree_model = DecisionTreeRegressor(min_samples_split=100,\n        max_features=\"auto\", random_state=50, \n        max_depth=100)\nmy_decision_tree_model.fit(train_X, train_y)\n\nevaluate(my_decision_tree_model, val_X, val_y)\n\npred_classes = my_decision_tree_model.predict(val_X)\npredi = []\nfor x in range(len(pred_classes)):\n    predi.append(bool(pred_classes[x]))\n    \npred_classes = np.array(predi)\n\nf1 = f1_score(val_y, pred_classes)\nprint('F1 score: %f' % f1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ADA Boost model"},{"metadata":{"trusted":true},"cell_type":"code","source":"Ada_boost_model = AdaBoostRegressor()\nAda_boost_model.fit(train_X, train_y)\n\nevaluate(Ada_boost_model, val_X, val_y)\n\npred_classes = Ada_boost_model.predict(val_X)\npredi = []\nfor x in range(len(pred_classes)):\n    predi.append(bool(pred_classes[x]))\n    \npred_classes = np.array(predi)\n\nf1 = f1_score(val_y, pred_classes)\nprint('F1 score: %f' % f1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Grid Search model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nclf = LogisticRegression(C=1, penalty='l1', solver='liblinear')\nparam_grid = {'C':[0.001,.009,0.01,.09,1,5,10,25]}\n'''{\n    'n_estimators' : [10, 200],\n    'max_features' : ['auto', 'sqrt', 'log2', 0.5]\n}'''\ngs_model = GridSearchCV(clf, param_grid = param_grid, scoring = 'recall')\ngs_model.fit(train_X, train_y)\n\npredictions = gs_model.predict(val_X)\naccuracy = accuracy_score(val_y, predictions.round())\nprint('Accuracy:%f'%accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n#def create_baseline():\n'''\nmodel = Sequential()\nmodel.add(Dense(7, activation='relu'))\nmodel.add(Dense(7, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(7, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(7, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(7, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(7, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(7, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(7, activation='relu'))\n#model.add(Dropout(0.4))\nmodel.add(Dense(1, activation='softmax'))\n#model.add(Dense(1, activation='sigmoid'))\n#model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\nmodel.compile(loss='mse', optimizer='Adam', metrics=[tf.keras.metrics.MeanSquaredError(),tf.keras.metrics.Accuracy()])\n#tf.keras.metrics.BinaryAccuracy()\n#adam,sgd\n#return model\n'''\nfrom keras.layers import BatchNormalization\nmodel = Sequential()\nmodel.add(Dense(15))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\nmodel.add(Dense(256,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(128,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(64,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(32,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(16,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(8,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(1,activation='softmax'))\n\nmodel.compile(optimizer='adam',loss='mse', metrics=['accuracy',f1_m])\n#model.compile(loss=keras.losses.categorical_crossentropy,optimizer='adam',metrics=['accuracy'])\n\n#estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=10, verbose=0)\n#kfold = StratifiedKFold(n_splits=10, shuffle=True)\n#results = cross_val_score(estimator, train_X, train_y, cv=kfold)\n#print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\nmodel.fit(train_X_.values, train_y_.values,\n          batch_size=20,\n          epochs=5,\n          validation_split = 0.2,\n          verbose = 1,\n          shuffle=True)\n\n#evaluate(model, val_X, val_y)\npred_classes = model.predict(val_X)\npredi = []\nfor x in range(len(pred_classes)):\n    predi.append(bool(pred_classes[x]))\n    \npred_classes = np.array(predi)\n\nf1 = f1_score(val_y, pred_classes)\nprint('F1 score: %f' % f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg_model = xgboost.XGBClassifier(base_score=0.1, booster= None, colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\n              gamma=0.4, gpu_id=0, importance_type='gain',\n              interaction_constraints=None, learning_rate=0.01,\n              max_delta_step=0, max_depth=80, min_child_weight=7, missing=None,\n              monotone_constraints=None, n_estimators=1000, n_jobs=6, nthread=6,\n              num_parallel_tree=1, objective='binary:logistic', random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, silent=False,\n              subsample=0.8,tree_method='hist', validate_parameters=False,\n              verbosity=1)\n#xg_model = xgboost.XGBClassifier()\n#base_score 0.5 -> 0.1\n#score=cross_val_score(xg_model, train_X, train_y, cv=10)\nxg_model.fit(train_X, train_y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def xg_evaluate(model, test_features, test_labels):\n    predictions = model.predict(test_features)\n    #mse = mean_squared_error(test_labels, predictions)\n    #mae = mean_absolute_error(test_labels, predictions)\n    #rmse = np.sqrt(mse)\n    #score=cross_val_score(model, test_features, test_labels, cv=10)\n    accuracy = accuracy_score(test_labels, predictions.round())\n    #print('Model Performance')\n    print('Accuracy:%f'%accuracy)\n    #print(\"Mean cross validation score:%f\"%score.mean())\n    #print('Mean Squared Error : %.4f' % mse)\n    #print('Root MSE : %.4f' % rmse)\nxg_evaluate(xg_model, val_X, val_y)\npred_classes = xg_model.predict(val_X)\npredi = []\nfor x in range(len(pred_classes)):\n    predi.append(bool(pred_classes[x]))\n    \npred_classes = np.array(predi)\n\nf1 = f1_score(val_y, pred_classes)\nprint('F1 score: %f' % f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn_classifier = KNeighborsClassifier(n_neighbors=7)\nknn_classifier.fit(train_X, train_y)\n\ndef knn_evaluate(model, test_features, test_labels):\n    predictions = model.predict(test_features)\n    #mse = mean_squared_error(test_labels, predictions)\n    #mae = mean_absolute_error(test_labels, predictions)\n    #rmse = np.sqrt(mse)\n    #score=cross_val_score(model, test_features, test_labels, cv=10)\n    accuracy = accuracy_score(test_labels, predictions.round())\n    #print('Model Performance')\n    print('Accuracy:%f'%accuracy)\n    #print(\"Mean cross validation score:%f\"%score.mean())\n    #print('Mean Squared Error : %.4f' % mse)\n    #print('Root MSE : %.4f' % rmse)\nknn_evaluate(knn_classifier, val_X, val_y)\n\npred_classes = knn_classifier.predict(val_X)\npredi = []\nfor x in range(len(pred_classes)):\n    predi.append(bool(pred_classes[x]))\n    \npred_classes = np.array(predi)\n\nf1 = f1_score(val_y, pred_classes)\nprint('F1 score: %f' % f1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_rf = my_random_forest_model.predict(test_X)\npredicted_dt = my_decision_tree_model.predict(test_X)\npredicted_ad = Ada_boost_model.predict(test_X)\npredicted_xg = xg_model.predict(test_X)\npredicted_NN = model.predict(test_X)\npredicted_KNN = knn_classifier.predict(test_X)\n\npred_KNN = []\nfor x in range(len(predicted_KNN)):\n    pred_KNN.append(bool(predicted_KNN[x]))\n\npredicted_KNN = np.array(pred_KNN)\n\npred_NN = []\nfor x in range(len(predicted_NN)):\n    pred_NN.append(bool(predicted_NN[x]))\n\npredicted_NN = np.array(pred_NN)\n    \npred_rf = []\nfor x in range(len(predicted_rf)):\n    pred_rf.append(bool(predicted_rf[x]))\n    \npredicted_rf = np.array(pred_rf)\n    \npred_dt = []\nfor x in range(len(predicted_dt)):\n    pred_dt.append(bool(predicted_dt[x]))\n\npredicted_dt = np.array(pred_dt)\n\npred_ad = []\nfor x in range(len(predicted_ad)):\n    pred_ad.append(bool(predicted_ad[x]))\n\npredicted_ad = np.array(pred_ad)\n\npred_xg = []\nfor x in range(len(predicted_xg)):\n    pred_xg.append(bool(predicted_xg[x]))\n    \npredicted_xg = np.array(pred_xg)\n\noutput_rf = pd.DataFrame({'tripid': test.tripid,\n                       'prediction': predicted_rf})\n\noutput_dt = pd.DataFrame({'tripid': test.tripid,\n                       'prediction': predicted_dt})\n\noutput_adb = pd.DataFrame({'tripid': test.tripid,\n                       'prediction': predicted_dt})\n\noutput_xg = pd.DataFrame({'tripid': test.tripid,\n                       'prediction': predicted_xg})\n\noutput_NN = pd.DataFrame({'tripid': test.tripid,\n                       'prediction': predicted_NN})\n\noutput_KNN = pd.DataFrame({'tripid': test.tripid,\n                       'prediction': predicted_KNN})\n\noutput_rf_path = \"submission_rf.csv\"\noutput_dt_path = \"submission_dt.csv\"\noutput_adb_path = \"submission_adb.csv\"\noutput_xg_path = \"submission_xg.csv\"\noutput_NN_path = \"submission_nn.csv\"\noutput_KNN_path = \"submission_knn.csv\"\n\noutput_rf.to_csv(output_rf_path, index=False)\noutput_dt.to_csv(output_dt_path, index=False)\noutput_adb.to_csv(output_adb_path, index = False)\noutput_xg.to_csv(output_xg_path, index = False)\noutput_NN.to_csv(output_NN_path, index = False)\noutput_KNN.to_csv(output_KNN_path, index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}