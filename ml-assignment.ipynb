{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing important modules and setting up the project"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.naive_bayes import GaussianNB\n\nfrom tensorflow.python import keras\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\n\nimport xgboost\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nimport tensorflow as tf\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/fare-classification/meta_data.csv\n/kaggle/input/my-sample-data/train.csv\n/kaggle/input/my-sample-data/test.csv\n","name":"stdout"},{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"Reading the data from files"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/my-sample-data/train.csv')\ntest = pd.read_csv('../input/my-sample-data/test.csv')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"      tripid  additional_fare  duration  meter_waiting  meter_waiting_fare  \\\n0  189123628             10.5     834.0           56.0              0.0000   \n1  189125358             10.5     791.0           47.0              0.0000   \n2  189125719             10.5    1087.0           80.0              0.0000   \n3  189127273             10.5     598.0          271.0             15.6638   \n4  189128020              NaN       NaN            NaN                 NaN   \n\n   meter_waiting_till_pickup     pickup_time       drop_time  pick_lat  \\\n0                       64.0  11/1/2019 0:20  11/1/2019 0:34   6.86252   \n1                      134.0  11/1/2019 0:56  11/1/2019 1:09   6.88589   \n2                       61.0  11/1/2019 1:08  11/1/2019 1:26   6.90839   \n3                       68.0  11/1/2019 2:27  11/1/2019 2:37   6.92570   \n4                        NaN  11/1/2019 3:34  11/1/2019 3:51   6.87441   \n\n   pick_lon  drop_lat  drop_lon    fare    label  \n0   79.8993   6.90330   79.8783  270.32  correct  \n1   79.8984   6.91373   79.8923  197.85  correct  \n2   79.8651   6.93669   79.9146  301.64  correct  \n3   79.8895   6.92748   79.8971   82.30  correct  \n4   79.8615   6.84478   79.9290  358.39  correct  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tripid</th>\n      <th>additional_fare</th>\n      <th>duration</th>\n      <th>meter_waiting</th>\n      <th>meter_waiting_fare</th>\n      <th>meter_waiting_till_pickup</th>\n      <th>pickup_time</th>\n      <th>drop_time</th>\n      <th>pick_lat</th>\n      <th>pick_lon</th>\n      <th>drop_lat</th>\n      <th>drop_lon</th>\n      <th>fare</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>189123628</td>\n      <td>10.5</td>\n      <td>834.0</td>\n      <td>56.0</td>\n      <td>0.0000</td>\n      <td>64.0</td>\n      <td>11/1/2019 0:20</td>\n      <td>11/1/2019 0:34</td>\n      <td>6.86252</td>\n      <td>79.8993</td>\n      <td>6.90330</td>\n      <td>79.8783</td>\n      <td>270.32</td>\n      <td>correct</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>189125358</td>\n      <td>10.5</td>\n      <td>791.0</td>\n      <td>47.0</td>\n      <td>0.0000</td>\n      <td>134.0</td>\n      <td>11/1/2019 0:56</td>\n      <td>11/1/2019 1:09</td>\n      <td>6.88589</td>\n      <td>79.8984</td>\n      <td>6.91373</td>\n      <td>79.8923</td>\n      <td>197.85</td>\n      <td>correct</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>189125719</td>\n      <td>10.5</td>\n      <td>1087.0</td>\n      <td>80.0</td>\n      <td>0.0000</td>\n      <td>61.0</td>\n      <td>11/1/2019 1:08</td>\n      <td>11/1/2019 1:26</td>\n      <td>6.90839</td>\n      <td>79.8651</td>\n      <td>6.93669</td>\n      <td>79.9146</td>\n      <td>301.64</td>\n      <td>correct</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>189127273</td>\n      <td>10.5</td>\n      <td>598.0</td>\n      <td>271.0</td>\n      <td>15.6638</td>\n      <td>68.0</td>\n      <td>11/1/2019 2:27</td>\n      <td>11/1/2019 2:37</td>\n      <td>6.92570</td>\n      <td>79.8895</td>\n      <td>6.92748</td>\n      <td>79.8971</td>\n      <td>82.30</td>\n      <td>correct</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>189128020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11/1/2019 3:34</td>\n      <td>11/1/2019 3:51</td>\n      <td>6.87441</td>\n      <td>79.8615</td>\n      <td>6.84478</td>\n      <td>79.9290</td>\n      <td>358.39</td>\n      <td>correct</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictor_cols = ['additional_fare', 'duration', 'meter_waiting', 'meter_waiting_fare', 'meter_waiting_till_pickup', 'fare']\ntrain_X = train[predictor_cols]\ntest_X = test[predictor_cols]\n\n#train_y.fillna(train_y.mean(), inplace=True)\ntrain_X.fillna(train_X.mean(), inplace=True)\ntest_X.fillna(test_X.mean(), inplace=True)\ntrain['num_label'] = False\ntrain['direct_distance'] = 0.0\ntest['direct_distance'] = 0.0\n\nfor index, row in train.iterrows():\n    train.at[index,'direct_distance'] = ((((row['drop_lon'] - row['pick_lon'])**2)+((row['drop_lat'] - row['pick_lat'])**2))**0.5)*111\n    \nfor index, row in test.iterrows():\n    test.at[index,'direct_distance'] = ((((row['drop_lon'] - row['pick_lon'])**2)+((row['drop_lat'] - row['pick_lat'])**2))**0.5)*111\n\nfor index, row in train.iterrows():\n    if(row['label'] == \"correct\"):\n        train.at[index, 'num_label'] = 1\n    else:\n        train.at[index, 'num_label'] = 0\n\npredictor_cols = ['additional_fare', 'direct_distance', 'duration', 'meter_waiting', 'meter_waiting_fare', 'meter_waiting_till_pickup', 'fare']\ntrain_X_ = train[predictor_cols]\ntest_X = test[predictor_cols]\ntrain_X_.fillna(train_X.mean(), inplace=True)\ntest_X.fillna(test_X.mean(), inplace=True)\n\ntrain_y_ = train.num_label\n#train_y = train['label']","execution_count":4,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py:6245: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._update_inplace(new_data)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X_.head()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"   additional_fare  direct_distance     duration  meter_waiting  \\\n0        10.500000         5.091511   834.000000      56.000000   \n1        10.500000         3.163550   791.000000      47.000000   \n2        10.500000         6.329083  1087.000000      80.000000   \n3        10.500000         0.866429   598.000000     271.000000   \n4        13.719651         8.182580  1702.858077     629.074231   \n\n   meter_waiting_fare  meter_waiting_till_pickup    fare  \n0            0.000000                  64.000000  270.32  \n1            0.000000                 134.000000  197.85  \n2            0.000000                  61.000000  301.64  \n3           15.663800                  68.000000   82.30  \n4           32.057666                 112.466832  358.39  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>additional_fare</th>\n      <th>direct_distance</th>\n      <th>duration</th>\n      <th>meter_waiting</th>\n      <th>meter_waiting_fare</th>\n      <th>meter_waiting_till_pickup</th>\n      <th>fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10.500000</td>\n      <td>5.091511</td>\n      <td>834.000000</td>\n      <td>56.000000</td>\n      <td>0.000000</td>\n      <td>64.000000</td>\n      <td>270.32</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10.500000</td>\n      <td>3.163550</td>\n      <td>791.000000</td>\n      <td>47.000000</td>\n      <td>0.000000</td>\n      <td>134.000000</td>\n      <td>197.85</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10.500000</td>\n      <td>6.329083</td>\n      <td>1087.000000</td>\n      <td>80.000000</td>\n      <td>0.000000</td>\n      <td>61.000000</td>\n      <td>301.64</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10.500000</td>\n      <td>0.866429</td>\n      <td>598.000000</td>\n      <td>271.000000</td>\n      <td>15.663800</td>\n      <td>68.000000</td>\n      <td>82.30</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13.719651</td>\n      <td>8.182580</td>\n      <td>1702.858077</td>\n      <td>629.074231</td>\n      <td>32.057666</td>\n      <td>112.466832</td>\n      <td>358.39</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X, val_X, train_y, val_y = train_test_split(train_X_, train_y_, test_size = 0.2, train_size = 0.8, random_state = 0)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, test_features, test_labels):\n    predictions = model.predict(test_features)\n    mse = mean_squared_error(test_labels, predictions)\n    mae = mean_absolute_error(test_labels, predictions)\n    rmse = np.sqrt(mse)\n    score=cross_val_score(model, test_features, test_labels, cv=10)\n    accuracy = accuracy_score(test_labels, predictions.round())\n    print('Model Performance')\n    print('Accuracy:%f'%accuracy)\n    print(\"Mean cross validation score:%f\"%score.mean())\n    print('Mean Squared Error : %.4f' % mse)\n    print('Root MSE : %.4f' % rmse)","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random forest model"},{"metadata":{"trusted":true},"cell_type":"code","source":"my_random_forest_model = RandomForestRegressor()\nmy_random_forest_model.fit(train_X, train_y)\n\nevaluate(my_random_forest_model, val_X, val_y)","execution_count":8,"outputs":[{"output_type":"stream","text":"Model Performance\nAccuracy:0.952270\nMean cross validation score:0.484992\nMean Squared Error : 0.0386\nRoot MSE : 0.1965\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Decision tree model"},{"metadata":{"trusted":true},"cell_type":"code","source":"my_decision_tree_model = DecisionTreeRegressor()\nmy_decision_tree_model.fit(train_X, train_y)\n\nevaluate(my_decision_tree_model, val_X, val_y)","execution_count":9,"outputs":[{"output_type":"stream","text":"Model Performance\nAccuracy:0.923458\nMean cross validation score:-0.003552\nMean Squared Error : 0.0765\nRoot MSE : 0.2767\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Ada_boost_model = AdaBoostRegressor()\nAda_boost_model.fit(train_X, train_y)\n\nevaluate(Ada_boost_model, val_X, val_y)","execution_count":10,"outputs":[{"output_type":"stream","text":"Model Performance\nAccuracy:0.925495\nMean cross validation score:0.045078\nMean Squared Error : 0.0762\nRoot MSE : 0.2760\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#def create_baseline():\nmodel = Sequential()\nmodel.add(Dense(7, activation='relu'))\nmodel.add(Dense(7, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(7, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(7, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(7, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(7, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(7, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(7, activation='relu'))\n#model.add(Dropout(0.4))\nmodel.add(Dense(1, activation='softmax'))\n#model.add(Dense(1, activation='sigmoid'))\n#model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\nmodel.compile(loss='mse', optimizer='Adam', metrics=[tf.keras.metrics.MeanSquaredError(),tf.keras.metrics.Accuracy()])\n#tf.keras.metrics.BinaryAccuracy()\n#adam,sgd\n#return model\n\n#model.compile(loss=keras.losses.categorical_crossentropy,optimizer='adam',metrics=['accuracy'])\n\n#estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=10, verbose=0)\n#kfold = StratifiedKFold(n_splits=10, shuffle=True)\n#results = cross_val_score(estimator, train_X, train_y, cv=kfold)\n#print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\nmodel.fit(train_X_.values, train_y_.values,\n          batch_size=10,\n          epochs=30,\n          validation_split = 0.5,\n          verbose = 1,\n          shuffle=True)\n\n#evaluate(model, val_X, val_y)","execution_count":11,"outputs":[{"output_type":"stream","text":"Train on 8588 samples, validate on 8588 samples\nEpoch 1/30\n8588/8588 [==============================] - 4s 416us/step - loss: 0.1164 - mean_squared_error: 0.1196 - accuracy: 0.8804 - val_loss: 0.0793 - val_mean_squared_error: 0.1037 - val_accuracy: 0.8963\nEpoch 2/30\n8588/8588 [==============================] - 3s 322us/step - loss: 0.1164 - mean_squared_error: 0.1008 - accuracy: 0.8992 - val_loss: 0.0793 - val_mean_squared_error: 0.1001 - val_accuracy: 0.8999\nEpoch 3/30\n8588/8588 [==============================] - 3s 345us/step - loss: 0.1164 - mean_squared_error: 0.0999 - accuracy: 0.9001 - val_loss: 0.0793 - val_mean_squared_error: 0.0992 - val_accuracy: 0.9008\nEpoch 4/30\n8588/8588 [==============================] - 3s 355us/step - loss: 0.1164 - mean_squared_error: 0.0991 - accuracy: 0.9009 - val_loss: 0.0793 - val_mean_squared_error: 0.0989 - val_accuracy: 0.9011\nEpoch 5/30\n8588/8588 [==============================] - 3s 358us/step - loss: 0.1164 - mean_squared_error: 0.0989 - accuracy: 0.9011 - val_loss: 0.0793 - val_mean_squared_error: 0.0986 - val_accuracy: 0.9014\nEpoch 6/30\n8588/8588 [==============================] - 3s 344us/step - loss: 0.1164 - mean_squared_error: 0.0987 - accuracy: 0.9013 - val_loss: 0.0793 - val_mean_squared_error: 0.0985 - val_accuracy: 0.9015\nEpoch 7/30\n8588/8588 [==============================] - 3s 328us/step - loss: 0.1164 - mean_squared_error: 0.0987 - accuracy: 0.9013 - val_loss: 0.0793 - val_mean_squared_error: 0.0984 - val_accuracy: 0.9016\nEpoch 8/30\n8588/8588 [==============================] - 3s 333us/step - loss: 0.1164 - mean_squared_error: 0.0985 - accuracy: 0.9015 - val_loss: 0.0793 - val_mean_squared_error: 0.0983 - val_accuracy: 0.9017\nEpoch 9/30\n8588/8588 [==============================] - 3s 325us/step - loss: 0.1164 - mean_squared_error: 0.0984 - accuracy: 0.9016 - val_loss: 0.0793 - val_mean_squared_error: 0.0983 - val_accuracy: 0.9017\nEpoch 10/30\n8588/8588 [==============================] - 3s 324us/step - loss: 0.1164 - mean_squared_error: 0.0983 - accuracy: 0.9017 - val_loss: 0.0793 - val_mean_squared_error: 0.0982 - val_accuracy: 0.9018\nEpoch 11/30\n8588/8588 [==============================] - 3s 321us/step - loss: 0.1164 - mean_squared_error: 0.0983 - accuracy: 0.9017 - val_loss: 0.0793 - val_mean_squared_error: 0.0982 - val_accuracy: 0.9018\nEpoch 12/30\n8588/8588 [==============================] - 3s 326us/step - loss: 0.1164 - mean_squared_error: 0.0982 - accuracy: 0.9018 - val_loss: 0.0793 - val_mean_squared_error: 0.0982 - val_accuracy: 0.9018\nEpoch 13/30\n8588/8588 [==============================] - 3s 322us/step - loss: 0.1164 - mean_squared_error: 0.0983 - accuracy: 0.9017 - val_loss: 0.0793 - val_mean_squared_error: 0.0982 - val_accuracy: 0.9018\nEpoch 14/30\n8588/8588 [==============================] - 3s 323us/step - loss: 0.1164 - mean_squared_error: 0.0982 - accuracy: 0.9018 - val_loss: 0.0793 - val_mean_squared_error: 0.0981 - val_accuracy: 0.9019\nEpoch 15/30\n8588/8588 [==============================] - 3s 320us/step - loss: 0.1164 - mean_squared_error: 0.0982 - accuracy: 0.9018 - val_loss: 0.0793 - val_mean_squared_error: 0.0981 - val_accuracy: 0.9019\nEpoch 16/30\n8588/8588 [==============================] - 3s 323us/step - loss: 0.1164 - mean_squared_error: 0.0982 - accuracy: 0.9018 - val_loss: 0.0793 - val_mean_squared_error: 0.0981 - val_accuracy: 0.9019\nEpoch 17/30\n8588/8588 [==============================] - 3s 320us/step - loss: 0.1164 - mean_squared_error: 0.0981 - accuracy: 0.9019 - val_loss: 0.0793 - val_mean_squared_error: 0.0981 - val_accuracy: 0.9019\nEpoch 18/30\n8588/8588 [==============================] - 3s 320us/step - loss: 0.1164 - mean_squared_error: 0.0982 - accuracy: 0.9018 - val_loss: 0.0793 - val_mean_squared_error: 0.0981 - val_accuracy: 0.9019\nEpoch 19/30\n8588/8588 [==============================] - 3s 324us/step - loss: 0.1164 - mean_squared_error: 0.0982 - accuracy: 0.9018 - val_loss: 0.0793 - val_mean_squared_error: 0.0981 - val_accuracy: 0.9019\nEpoch 20/30\n8588/8588 [==============================] - 3s 325us/step - loss: 0.1164 - mean_squared_error: 0.0981 - accuracy: 0.9019 - val_loss: 0.0793 - val_mean_squared_error: 0.0981 - val_accuracy: 0.9019\nEpoch 21/30\n8588/8588 [==============================] - 3s 322us/step - loss: 0.1164 - mean_squared_error: 0.0981 - accuracy: 0.9019 - val_loss: 0.0793 - val_mean_squared_error: 0.0980 - val_accuracy: 0.9020\nEpoch 22/30\n8588/8588 [==============================] - 3s 319us/step - loss: 0.1164 - mean_squared_error: 0.0981 - accuracy: 0.9019 - val_loss: 0.0793 - val_mean_squared_error: 0.0980 - val_accuracy: 0.9020\nEpoch 23/30\n8588/8588 [==============================] - 3s 320us/step - loss: 0.1164 - mean_squared_error: 0.0981 - accuracy: 0.9019 - val_loss: 0.0793 - val_mean_squared_error: 0.0980 - val_accuracy: 0.9020\nEpoch 24/30\n8588/8588 [==============================] - 3s 322us/step - loss: 0.1164 - mean_squared_error: 0.0981 - accuracy: 0.9019 - val_loss: 0.0793 - val_mean_squared_error: 0.0980 - val_accuracy: 0.9020\nEpoch 25/30\n8588/8588 [==============================] - 3s 320us/step - loss: 0.1164 - mean_squared_error: 0.0981 - accuracy: 0.9019 - val_loss: 0.0793 - val_mean_squared_error: 0.0980 - val_accuracy: 0.9020\nEpoch 26/30\n8588/8588 [==============================] - 3s 334us/step - loss: 0.1164 - mean_squared_error: 0.0980 - accuracy: 0.9020 - val_loss: 0.0793 - val_mean_squared_error: 0.0980 - val_accuracy: 0.9020\nEpoch 27/30\n8588/8588 [==============================] - 3s 330us/step - loss: 0.1164 - mean_squared_error: 0.0980 - accuracy: 0.9020 - val_loss: 0.0793 - val_mean_squared_error: 0.0980 - val_accuracy: 0.9020\nEpoch 28/30\n8588/8588 [==============================] - 3s 330us/step - loss: 0.1164 - mean_squared_error: 0.0980 - accuracy: 0.9020 - val_loss: 0.0793 - val_mean_squared_error: 0.0980 - val_accuracy: 0.9020\nEpoch 29/30\n8588/8588 [==============================] - 3s 324us/step - loss: 0.1164 - mean_squared_error: 0.0981 - accuracy: 0.9019 - val_loss: 0.0793 - val_mean_squared_error: 0.0980 - val_accuracy: 0.9020\nEpoch 30/30\n8588/8588 [==============================] - 3s 321us/step - loss: 0.1164 - mean_squared_error: 0.0980 - accuracy: 0.9020 - val_loss: 0.0793 - val_mean_squared_error: 0.0980 - val_accuracy: 0.9020\n","name":"stdout"},{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7f00f2bdc910>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg_model = xgboost.XGBClassifier(base_score=0.1, booster= None, colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\n              gamma=0.4, gpu_id=0, importance_type='gain',\n              interaction_constraints=None, learning_rate=0.01,\n              max_delta_step=0, max_depth=80, min_child_weight=7, missing=None,\n              monotone_constraints=None, n_estimators=1000, n_jobs=6, nthread=6,\n              num_parallel_tree=1, objective='binary:logistic', random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, silent=False,\n              subsample=0.8,tree_method='hist', validate_parameters=False,\n              verbosity=1)\n#xg_model = xgboost.XGBClassifier()\n#base_score 0.5 -> 0.1\n#score=cross_val_score(xg_model, train_X, train_y, cv=10)\nxg_model.fit(train_X, train_y)\n","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"XGBClassifier(base_score=0.1, booster=None, colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\n              gamma=0.4, gpu_id=0, importance_type='gain',\n              interaction_constraints=None, learning_rate=0.01,\n              max_delta_step=0, max_depth=80, min_child_weight=7, missing=nan,\n              monotone_constraints=None, n_estimators=1000, n_jobs=6, nthread=6,\n              num_parallel_tree=1, objective='binary:logistic', random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, silent=False,\n              subsample=0.8, tree_method='hist', validate_parameters=False,\n              verbosity=1)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def xg_evaluate(model, test_features, test_labels):\n    predictions = model.predict(test_features)\n    #mse = mean_squared_error(test_labels, predictions)\n    #mae = mean_absolute_error(test_labels, predictions)\n    #rmse = np.sqrt(mse)\n    #score=cross_val_score(model, test_features, test_labels, cv=10)\n    accuracy = accuracy_score(test_labels, predictions.round())\n    #print('Model Performance')\n    print('Accuracy:%f'%accuracy)\n    #print(\"Mean cross validation score:%f\"%score.mean())\n    #print('Mean Squared Error : %.4f' % mse)\n    #print('Root MSE : %.4f' % rmse)\nxg_evaluate(xg_model, val_X, val_y)","execution_count":18,"outputs":[{"output_type":"stream","text":"Accuracy:0.951688\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn_classifier = KNeighborsClassifier(n_neighbors=7)\nknn_classifier.fit(train_X, train_y)\n\ndef knn_evaluate(model, test_features, test_labels):\n    predictions = model.predict(test_features)\n    #mse = mean_squared_error(test_labels, predictions)\n    #mae = mean_absolute_error(test_labels, predictions)\n    #rmse = np.sqrt(mse)\n    #score=cross_val_score(model, test_features, test_labels, cv=10)\n    accuracy = accuracy_score(test_labels, predictions.round())\n    #print('Model Performance')\n    print('Accuracy:%f'%accuracy)\n    #print(\"Mean cross validation score:%f\"%score.mean())\n    #print('Mean Squared Error : %.4f' % mse)\n    #print('Root MSE : %.4f' % rmse)\nknn_evaluate(classifier, val_X, val_y)\n'''\nfor i in range(1, 40):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(train_X, train_y)\n    knn_evaluate(classifier, val_X, val_y)'''","execution_count":26,"outputs":[{"output_type":"stream","text":"Accuracy:0.946740\n","name":"stdout"},{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"'\\nfor i in range(1, 40):\\n    knn = KNeighborsClassifier(n_neighbors=i)\\n    knn.fit(train_X, train_y)\\n    knn_evaluate(classifier, val_X, val_y)'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_rf = my_random_forest_model.predict(test_X)\npredicted_dt = my_decision_tree_model.predict(test_X)\npredicted_ad = Ada_boost_model.predict(test_X)\npredicted_xg = xg_model.predict(test_X)\npredicted_NN = model.predict(test_X)\npredicted_KNN = knn_classifier.predict(test_X)\n\npred_KNN = []\nfor x in range(len(predicted_KNN)):\n    pred_KNN.append(bool(predicted_KNN[x]))\n\npredicted_NN = np.array(pred_NN)\n\npred_NN = []\nfor x in range(len(predicted_NN)):\n    pred_NN.append(bool(predicted_NN[x]))\n\npredicted_NN = np.array(pred_NN)\n    \npred_rf = []\nfor x in range(len(predicted_rf)):\n    pred_rf.append(bool(predicted_rf[x]))\n    \npredicted_rf = np.array(pred_rf)\n    \npred_dt = []\nfor x in range(len(predicted_dt)):\n    pred_dt.append(bool(predicted_dt[x]))\n\npredicted_dt = np.array(pred_dt)\n\npred_ad = []\nfor x in range(len(predicted_ad)):\n    pred_ad.append(bool(predicted_ad[x]))\n\npredicted_ad = np.array(pred_ad)\n\npred_xg = []\nfor x in range(len(predicted_xg)):\n    pred_xg.append(bool(predicted_xg[x]))\n    \npredicted_xg = np.array(pred_xg)\n\noutput_rf = pd.DataFrame({'tripid': test.tripid,\n                       'prediction': predicted_rf})\n\noutput_dt = pd.DataFrame({'tripid': test.tripid,\n                       'prediction': predicted_dt})\n\noutput_adb = pd.DataFrame({'tripid': test.tripid,\n                       'prediction': predicted_dt})\n\noutput_xg = pd.DataFrame({'tripid': test.tripid,\n                       'prediction': predicted_xg})\n\noutput_NN = pd.DataFrame({'tripid': test.tripid,\n                       'prediction': predicted_NN})\n\noutput_KNN = pd.DataFrame({'tripid': test.tripid,\n                       'prediction': predicted_KNN})\n\noutput_rf_path = \"submission_rf.csv\"\noutput_dt_path = \"submission_dt.csv\"\noutput_adb_path = \"submission_adb.csv\"\noutput_xg_path = \"submission_xg.csv\"\noutput_NN_path = \"submission_nn.csv\"\noutput_KNN_path = \"submission_knn.csv\"\n\noutput_rf.to_csv(output_rf_path, index=False)\noutput_dt.to_csv(output_dt_path, index=False)\noutput_adb.to_csv(output_adb_path, index = False)\noutput_xg.to_csv(output_xg_path, index = False)\noutput_NN.to_csv(output_NN_path, index = False)\noutput_KNN.to_csv(output_KNN_path, index = False)","execution_count":27,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}