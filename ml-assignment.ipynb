{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing important modules and setting up the project"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import f1_score\n\nfrom tensorflow.python import keras\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\n\nimport xgboost\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Dropout\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nimport tensorflow as tf\nfrom keras import backend as K\n\nfrom sklearn.model_selection import GridSearchCV\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/my-sample-data/test.csv\n/kaggle/input/my-sample-data/train.csv\n/kaggle/input/fare-classification/meta_data.csv\n","name":"stdout"},{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"Reading the data from files"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/my-sample-data/train.csv')\ntest = pd.read_csv('../input/my-sample-data/test.csv')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"      tripid  additional_fare  duration  meter_waiting  meter_waiting_fare  \\\n0  189123628             10.5     834.0           56.0              0.0000   \n1  189125358             10.5     791.0           47.0              0.0000   \n2  189125719             10.5    1087.0           80.0              0.0000   \n3  189127273             10.5     598.0          271.0             15.6638   \n4  189128020              NaN       NaN            NaN                 NaN   \n\n   meter_waiting_till_pickup     pickup_time       drop_time  pick_lat  \\\n0                       64.0  11/1/2019 0:20  11/1/2019 0:34   6.86252   \n1                      134.0  11/1/2019 0:56  11/1/2019 1:09   6.88589   \n2                       61.0  11/1/2019 1:08  11/1/2019 1:26   6.90839   \n3                       68.0  11/1/2019 2:27  11/1/2019 2:37   6.92570   \n4                        NaN  11/1/2019 3:34  11/1/2019 3:51   6.87441   \n\n   pick_lon  drop_lat  drop_lon    fare    label  \n0   79.8993   6.90330   79.8783  270.32  correct  \n1   79.8984   6.91373   79.8923  197.85  correct  \n2   79.8651   6.93669   79.9146  301.64  correct  \n3   79.8895   6.92748   79.8971   82.30  correct  \n4   79.8615   6.84478   79.9290  358.39  correct  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tripid</th>\n      <th>additional_fare</th>\n      <th>duration</th>\n      <th>meter_waiting</th>\n      <th>meter_waiting_fare</th>\n      <th>meter_waiting_till_pickup</th>\n      <th>pickup_time</th>\n      <th>drop_time</th>\n      <th>pick_lat</th>\n      <th>pick_lon</th>\n      <th>drop_lat</th>\n      <th>drop_lon</th>\n      <th>fare</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>189123628</td>\n      <td>10.5</td>\n      <td>834.0</td>\n      <td>56.0</td>\n      <td>0.0000</td>\n      <td>64.0</td>\n      <td>11/1/2019 0:20</td>\n      <td>11/1/2019 0:34</td>\n      <td>6.86252</td>\n      <td>79.8993</td>\n      <td>6.90330</td>\n      <td>79.8783</td>\n      <td>270.32</td>\n      <td>correct</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>189125358</td>\n      <td>10.5</td>\n      <td>791.0</td>\n      <td>47.0</td>\n      <td>0.0000</td>\n      <td>134.0</td>\n      <td>11/1/2019 0:56</td>\n      <td>11/1/2019 1:09</td>\n      <td>6.88589</td>\n      <td>79.8984</td>\n      <td>6.91373</td>\n      <td>79.8923</td>\n      <td>197.85</td>\n      <td>correct</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>189125719</td>\n      <td>10.5</td>\n      <td>1087.0</td>\n      <td>80.0</td>\n      <td>0.0000</td>\n      <td>61.0</td>\n      <td>11/1/2019 1:08</td>\n      <td>11/1/2019 1:26</td>\n      <td>6.90839</td>\n      <td>79.8651</td>\n      <td>6.93669</td>\n      <td>79.9146</td>\n      <td>301.64</td>\n      <td>correct</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>189127273</td>\n      <td>10.5</td>\n      <td>598.0</td>\n      <td>271.0</td>\n      <td>15.6638</td>\n      <td>68.0</td>\n      <td>11/1/2019 2:27</td>\n      <td>11/1/2019 2:37</td>\n      <td>6.92570</td>\n      <td>79.8895</td>\n      <td>6.92748</td>\n      <td>79.8971</td>\n      <td>82.30</td>\n      <td>correct</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>189128020</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>11/1/2019 3:34</td>\n      <td>11/1/2019 3:51</td>\n      <td>6.87441</td>\n      <td>79.8615</td>\n      <td>6.84478</td>\n      <td>79.9290</td>\n      <td>358.39</td>\n      <td>correct</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"      tripid  additional_fare  duration  meter_waiting  meter_waiting_fare  \\\n0  213284604             10.5       924             42              2.4486   \n1  213286352             10.5      4249             20              0.0000   \n2  213293973             10.5      1552            255              2.6588   \n3  213294622             10.5       462             16              0.0000   \n4  213298687             10.5       814            392             12.3692   \n\n   meter_waiting_till_pickup    pickup_time      drop_time  pick_lat  \\\n0                        148  2/1/2020 0:38  2/1/2020 0:53   6.83454   \n1                         91  2/1/2020 1:02  2/1/2020 2:13   6.91168   \n2                         23  2/1/2020 5:02  2/1/2020 5:28   6.92145   \n3                        198  2/1/2020 5:30  2/1/2020 5:38   6.77433   \n4                         69  2/1/2020 7:00  2/1/2020 7:14   6.97968   \n\n   pick_lon  drop_lat  drop_lon     fare  \n0   79.8750   6.77490   79.8840   289.27  \n1   79.8723   6.55091   79.9706  1912.70  \n2   79.8478   6.90539   79.8989   394.00  \n3   79.9416   6.80401   79.9407   154.32  \n4   79.9130   6.98875   79.8914   147.47  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tripid</th>\n      <th>additional_fare</th>\n      <th>duration</th>\n      <th>meter_waiting</th>\n      <th>meter_waiting_fare</th>\n      <th>meter_waiting_till_pickup</th>\n      <th>pickup_time</th>\n      <th>drop_time</th>\n      <th>pick_lat</th>\n      <th>pick_lon</th>\n      <th>drop_lat</th>\n      <th>drop_lon</th>\n      <th>fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>213284604</td>\n      <td>10.5</td>\n      <td>924</td>\n      <td>42</td>\n      <td>2.4486</td>\n      <td>148</td>\n      <td>2/1/2020 0:38</td>\n      <td>2/1/2020 0:53</td>\n      <td>6.83454</td>\n      <td>79.8750</td>\n      <td>6.77490</td>\n      <td>79.8840</td>\n      <td>289.27</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>213286352</td>\n      <td>10.5</td>\n      <td>4249</td>\n      <td>20</td>\n      <td>0.0000</td>\n      <td>91</td>\n      <td>2/1/2020 1:02</td>\n      <td>2/1/2020 2:13</td>\n      <td>6.91168</td>\n      <td>79.8723</td>\n      <td>6.55091</td>\n      <td>79.9706</td>\n      <td>1912.70</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>213293973</td>\n      <td>10.5</td>\n      <td>1552</td>\n      <td>255</td>\n      <td>2.6588</td>\n      <td>23</td>\n      <td>2/1/2020 5:02</td>\n      <td>2/1/2020 5:28</td>\n      <td>6.92145</td>\n      <td>79.8478</td>\n      <td>6.90539</td>\n      <td>79.8989</td>\n      <td>394.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>213294622</td>\n      <td>10.5</td>\n      <td>462</td>\n      <td>16</td>\n      <td>0.0000</td>\n      <td>198</td>\n      <td>2/1/2020 5:30</td>\n      <td>2/1/2020 5:38</td>\n      <td>6.77433</td>\n      <td>79.9416</td>\n      <td>6.80401</td>\n      <td>79.9407</td>\n      <td>154.32</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>213298687</td>\n      <td>10.5</td>\n      <td>814</td>\n      <td>392</td>\n      <td>12.3692</td>\n      <td>69</td>\n      <td>2/1/2020 7:00</td>\n      <td>2/1/2020 7:14</td>\n      <td>6.97968</td>\n      <td>79.9130</td>\n      <td>6.98875</td>\n      <td>79.8914</td>\n      <td>147.47</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictor_cols = ['additional_fare', 'duration', 'meter_waiting', 'meter_waiting_fare', 'meter_waiting_till_pickup', 'fare']\ntrain_X = train[predictor_cols]\ntest_X = test[predictor_cols]\n\n#train_y.fillna(train_y.mean(), inplace=True)\ntrain.fillna(train_X.mean(), inplace=True)\ntest.fillna(test_X.mean(), inplace=True)\ntrain['num_label'] = False\ntrain['direct_distance'] = 0.0\ntest['direct_distance'] = 0.0\n\ntrain['pickup_time'] = pd.to_datetime(train['pickup_time'], errors='coerce')\ntest['pickup_time'] = pd.to_datetime(test['pickup_time'], errors='coerce')\n\ntrain['drop_time'] = pd.to_datetime(train['drop_time'], errors='coerce')\ntest['drop_time'] = pd.to_datetime(test['drop_time'], errors='coerce')\n\ntrain['pick_hour'] = train['pickup_time'].dt.hour\ntrain['drop_hour'] = train['drop_time'].dt.hour\n\ntest['pick_hour'] = test['pickup_time'].dt.hour\ntest['drop_hour'] = test['drop_time'].dt.hour\n\n\nfor index, row in train.iterrows():\n    lat1, lng1, lat2, lng2 = map(np.radians, (row['drop_lat'], row['drop_lon'], row['pick_lat'], row['pick_lon']))\n    lat = lat2 - lat1\n    lng = lng2 - lng1\n    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n    h = 2 * 6371 * np.arcsin(np.sqrt(d))\n    train.at[index,'direct_distance'] = 2 * 6371 * np.arcsin(np.sqrt(d))\n    #d = (((row['drop_lon'] - row['pick_lon'])**2)+((row['drop_lat'] - row['pick_lat'])**2))\n    #train.at[index,'direct_distance'] = 2 * 6371 * np.arcsin()\n    \nfor index, row in test.iterrows():\n    lat1, lng1, lat2, lng2 = map(np.radians, (row['drop_lat'], row['drop_lon'], row['pick_lat'], row['pick_lon']))\n    lat = lat2 - lat1\n    lng = lng2 - lng1\n    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n    h = 2 * 6371 * np.arcsin(np.sqrt(d))\n    test.at[index,'direct_distance'] = 2 * 6371 * np.arcsin(np.sqrt(d))\n\n\ntrain['fare_for_duration'] = (train['fare'] - train['meter_waiting_fare'])/train['duration']\n#train['fare_for_distance'] = (train['fare'] - train['meter_waiting_fare'])/train['direct_distance']\ntrain['fare_for_time'] = (train['fare'] - train['meter_waiting_fare'])/(train['duration']+train['meter_waiting_till_pickup'])\n#train['distance_for_time'] = train['direct_distance']/train['duration']\ntrain['meter_waiting_to_duration'] = train['meter_waiting']/train['duration']\ntrain['additional_fare_to_duration'] = train['additional_fare']/train['duration']\n#train['additional_fare_to_distance'] = train['additional_fare']/train['direct_distance']\ntrain['additional_fare_to_fare'] = train['additional_fare']/(train['fare']+train['additional_fare'])\ntrain['mtr_wating_fare_to_waiting_duration'] = train['meter_waiting_fare']/(train['meter_waiting']+train['meter_waiting_till_pickup'])\n\ntest['fare_for_duration'] = (test['fare'] - test['meter_waiting_fare'])/test['duration']\n#test['fare_for_distance'] = (test['fare'] - test['meter_waiting_fare'])/test['direct_distance']\ntest['fare_for_time'] = (test['fare'] - test['meter_waiting_fare'])/(test['duration']+test['meter_waiting_till_pickup'])\n#test['distance_for_time'] = test['direct_distance']/test['duration']\ntest['meter_waiting_to_duration'] = test['meter_waiting']/test['duration']\ntest['additional_fare_to_duration'] = test['additional_fare']/test['duration']\n#test['additional_fare_to_distance'] = test['additional_fare']/test['direct_distance']\ntest['additional_fare_to_fare'] = test['additional_fare']/(test['fare']+test['additional_fare'])\ntest['mtr_wating_fare_to_waiting_duration'] = test['meter_waiting_fare']/(test['meter_waiting']+test['meter_waiting_till_pickup'])\n\ntrain.replace([np.inf, -np.inf], np.nan)\ntest.replace([np.inf, -np.inf], np.nan)\ntrain.fillna(train.mean(), inplace=True)\ntest.fillna(test.mean(), inplace=True)\n\ntrain['fare_for_duration'] = train['fare_for_duration'].astype(np.float32)\n#train['fare_for_distance'] = train['fare_for_distance'].astype(np.float32)\ntrain['fare_for_time'] = train['fare_for_time'].astype(np.float32)\n#train['distance_for_time'] = train['distance_for_time'].astype(np.float32)\ntrain['meter_waiting_to_duration'] = train['meter_waiting_to_duration'].astype(np.float32)\ntrain['additional_fare_to_duration'] = train['additional_fare_to_duration'].astype(np.float32)\n#train['additional_fare_to_distance'] = train['additional_fare_to_distance'].astype(np.float32)\ntrain['additional_fare_to_fare'] = train['additional_fare_to_fare'].astype(np.float32)\ntrain['mtr_wating_fare_to_waiting_duration'] = train['mtr_wating_fare_to_waiting_duration'].astype(np.float32)\n\ntest['fare_for_duration'] = test['fare_for_duration'].astype(np.float32)\n#test['fare_for_distance'] = test['fare_for_distance'].astype(np.float32)\ntest['fare_for_time'] = test['fare_for_time'].astype(np.float32)\n#test['distance_for_time'] = test['distance_for_time'].astype(np.float32)\ntest['meter_waiting_to_duration'] = test['meter_waiting_to_duration'].astype(np.float32)\ntest['additional_fare_to_duration'] = test['additional_fare_to_duration'].astype(np.float32)\n#test['additional_fare_to_distance'] = test['additional_fare_to_distance'].astype(np.float32)\ntest['additional_fare_to_fare'] = test['additional_fare_to_fare'].astype(np.float32)\ntest['mtr_wating_fare_to_waiting_duration'] = test['mtr_wating_fare_to_waiting_duration'].astype(np.float32)\n\n\n\nfor index, row in train.iterrows():\n    if(row['label'] == \"correct\"):\n        train.at[index, 'num_label'] = 1\n    else:\n        train.at[index, 'num_label'] = 0\n\n\n#train_y = train['label']","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 'fare_for_distance',\n# 'distance_for_time', 'additional_fare_to_distance', 'distance_for_time', 'only_fare_for_duration',\npredictor_cols = ['additional_fare', 'mtr_wating_fare_to_waiting_duration', 'fare_for_time', 'meter_waiting_to_duration', 'fare_for_duration', 'additional_fare_to_duration', 'additional_fare_to_fare', 'pick_hour', 'drop_hour', 'pick_lat', 'pick_lon', 'direct_distance', 'duration', 'meter_waiting', 'meter_waiting_fare', 'meter_waiting_till_pickup', 'fare']\ntrain_X_ = train[predictor_cols]\ntest_X = test[predictor_cols]\ntrain_X_.replace([np.inf, -np.inf], np.nan)\ntest_X.replace([np.inf, -np.inf], np.nan)\ntrain_X_.fillna(train_X_.mean(), inplace=True)\ntest_X.fillna(test_X.mean(), inplace=True)\n\ntrain_y_ = train.num_label","execution_count":23,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py:6245: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._update_inplace(new_data)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X_","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"       additional_fare  fare_for_distance  \\\n0            10.500000          53.079170   \n1            10.500000          62.451515   \n2            10.500000          47.838398   \n3            10.500000          77.309006   \n4            13.719651          40.051678   \n...                ...                ...   \n17171        10.500000          91.593201   \n17172        10.500000          53.479004   \n17173        10.500000          72.882500   \n17174        10.500000          46.303036   \n17175        10.500000          46.007301   \n\n       mtr_wating_fare_to_waiting_duration  fare_for_time  \\\n0                                 0.000000       0.301024   \n1                                 0.000000       0.213892   \n2                                 0.000000       0.262753   \n3                                 0.046206       0.100054   \n4                                 0.043231       0.179765   \n...                                    ...            ...   \n17171                             0.009967       0.149603   \n17172                             0.000000       0.265402   \n17173                             0.000000       0.204290   \n17174                             0.000000       0.113455   \n17175                             0.027825       0.341564   \n\n       meter_waiting_to_duration  fare_for_duration  \\\n0                       0.067146           0.324125   \n1                       0.059418           0.250126   \n2                       0.073597           0.277498   \n3                       0.453177           0.111432   \n4                       0.369423           0.191638   \n...                          ...                ...   \n17171                   0.110979           0.230117   \n17172                   0.198977           0.270214   \n17173                   0.034221           0.289734   \n17174                   0.134033           0.155373   \n17175                   0.080153           0.371548   \n\n       additional_fare_to_duration  additional_fare_to_fare  pick_hour  \\\n0                         0.012590                 0.037391          0   \n1                         0.013274                 0.050396          0   \n2                         0.009660                 0.033639          1   \n3                         0.017559                 0.113147          2   \n4                         0.008057                 0.036870          3   \n...                            ...                      ...        ...   \n17171                     0.012530                 0.050297         22   \n17172                     0.004881                 0.017745         23   \n17173                     0.039924                 0.121107         23   \n17174                     0.012238                 0.073013         23   \n17175                     0.040076                 0.096268         23   \n\n       drop_hour  pick_lat  pick_lon  direct_distance     duration  \\\n0              0   6.86252   79.8993         5.092770   834.000000   \n1              1   6.88589   79.8984         3.168058   791.000000   \n2              1   6.90839   79.8651         6.305395  1087.000000   \n3              2   6.92570   79.8895         0.861946   598.000000   \n4              3   6.87441   79.8615         8.147782  1702.858077   \n...          ...       ...       ...              ...          ...   \n17171         22   7.29073   80.6367         2.105376   838.000000   \n17172         23   6.90569   79.8516        10.868377  2151.000000   \n17173         23   7.09210   79.9000         1.045518   263.000000   \n17174         23   6.94540   79.8768         2.879077   858.000000   \n17175         23   6.90257   79.9557         2.115875   262.000000   \n\n       meter_waiting  meter_waiting_fare  meter_waiting_till_pickup    fare  \n0          56.000000            0.000000                  64.000000  270.32  \n1          47.000000            0.000000                 134.000000  197.85  \n2          80.000000            0.000000                  61.000000  301.64  \n3         271.000000           15.663800                  68.000000   82.30  \n4         629.074231           32.057666                 112.466832  358.39  \n...              ...                 ...                        ...     ...  \n17171      93.000000            5.421900                 451.000000  198.26  \n17172     428.000000            0.000000                  39.000000  581.23  \n17173       9.000000            0.000000                 110.000000   76.20  \n17174     115.000000            0.000000                 317.000000  133.31  \n17175      21.000000            1.224300                  23.000000   98.57  \n\n[17176 rows x 18 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>additional_fare</th>\n      <th>fare_for_distance</th>\n      <th>mtr_wating_fare_to_waiting_duration</th>\n      <th>fare_for_time</th>\n      <th>meter_waiting_to_duration</th>\n      <th>fare_for_duration</th>\n      <th>additional_fare_to_duration</th>\n      <th>additional_fare_to_fare</th>\n      <th>pick_hour</th>\n      <th>drop_hour</th>\n      <th>pick_lat</th>\n      <th>pick_lon</th>\n      <th>direct_distance</th>\n      <th>duration</th>\n      <th>meter_waiting</th>\n      <th>meter_waiting_fare</th>\n      <th>meter_waiting_till_pickup</th>\n      <th>fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10.500000</td>\n      <td>53.079170</td>\n      <td>0.000000</td>\n      <td>0.301024</td>\n      <td>0.067146</td>\n      <td>0.324125</td>\n      <td>0.012590</td>\n      <td>0.037391</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6.86252</td>\n      <td>79.8993</td>\n      <td>5.092770</td>\n      <td>834.000000</td>\n      <td>56.000000</td>\n      <td>0.000000</td>\n      <td>64.000000</td>\n      <td>270.32</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10.500000</td>\n      <td>62.451515</td>\n      <td>0.000000</td>\n      <td>0.213892</td>\n      <td>0.059418</td>\n      <td>0.250126</td>\n      <td>0.013274</td>\n      <td>0.050396</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6.88589</td>\n      <td>79.8984</td>\n      <td>3.168058</td>\n      <td>791.000000</td>\n      <td>47.000000</td>\n      <td>0.000000</td>\n      <td>134.000000</td>\n      <td>197.85</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10.500000</td>\n      <td>47.838398</td>\n      <td>0.000000</td>\n      <td>0.262753</td>\n      <td>0.073597</td>\n      <td>0.277498</td>\n      <td>0.009660</td>\n      <td>0.033639</td>\n      <td>1</td>\n      <td>1</td>\n      <td>6.90839</td>\n      <td>79.8651</td>\n      <td>6.305395</td>\n      <td>1087.000000</td>\n      <td>80.000000</td>\n      <td>0.000000</td>\n      <td>61.000000</td>\n      <td>301.64</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10.500000</td>\n      <td>77.309006</td>\n      <td>0.046206</td>\n      <td>0.100054</td>\n      <td>0.453177</td>\n      <td>0.111432</td>\n      <td>0.017559</td>\n      <td>0.113147</td>\n      <td>2</td>\n      <td>2</td>\n      <td>6.92570</td>\n      <td>79.8895</td>\n      <td>0.861946</td>\n      <td>598.000000</td>\n      <td>271.000000</td>\n      <td>15.663800</td>\n      <td>68.000000</td>\n      <td>82.30</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>13.719651</td>\n      <td>40.051678</td>\n      <td>0.043231</td>\n      <td>0.179765</td>\n      <td>0.369423</td>\n      <td>0.191638</td>\n      <td>0.008057</td>\n      <td>0.036870</td>\n      <td>3</td>\n      <td>3</td>\n      <td>6.87441</td>\n      <td>79.8615</td>\n      <td>8.147782</td>\n      <td>1702.858077</td>\n      <td>629.074231</td>\n      <td>32.057666</td>\n      <td>112.466832</td>\n      <td>358.39</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>17171</th>\n      <td>10.500000</td>\n      <td>91.593201</td>\n      <td>0.009967</td>\n      <td>0.149603</td>\n      <td>0.110979</td>\n      <td>0.230117</td>\n      <td>0.012530</td>\n      <td>0.050297</td>\n      <td>22</td>\n      <td>22</td>\n      <td>7.29073</td>\n      <td>80.6367</td>\n      <td>2.105376</td>\n      <td>838.000000</td>\n      <td>93.000000</td>\n      <td>5.421900</td>\n      <td>451.000000</td>\n      <td>198.26</td>\n    </tr>\n    <tr>\n      <th>17172</th>\n      <td>10.500000</td>\n      <td>53.479004</td>\n      <td>0.000000</td>\n      <td>0.265402</td>\n      <td>0.198977</td>\n      <td>0.270214</td>\n      <td>0.004881</td>\n      <td>0.017745</td>\n      <td>23</td>\n      <td>23</td>\n      <td>6.90569</td>\n      <td>79.8516</td>\n      <td>10.868377</td>\n      <td>2151.000000</td>\n      <td>428.000000</td>\n      <td>0.000000</td>\n      <td>39.000000</td>\n      <td>581.23</td>\n    </tr>\n    <tr>\n      <th>17173</th>\n      <td>10.500000</td>\n      <td>72.882500</td>\n      <td>0.000000</td>\n      <td>0.204290</td>\n      <td>0.034221</td>\n      <td>0.289734</td>\n      <td>0.039924</td>\n      <td>0.121107</td>\n      <td>23</td>\n      <td>23</td>\n      <td>7.09210</td>\n      <td>79.9000</td>\n      <td>1.045518</td>\n      <td>263.000000</td>\n      <td>9.000000</td>\n      <td>0.000000</td>\n      <td>110.000000</td>\n      <td>76.20</td>\n    </tr>\n    <tr>\n      <th>17174</th>\n      <td>10.500000</td>\n      <td>46.303036</td>\n      <td>0.000000</td>\n      <td>0.113455</td>\n      <td>0.134033</td>\n      <td>0.155373</td>\n      <td>0.012238</td>\n      <td>0.073013</td>\n      <td>23</td>\n      <td>23</td>\n      <td>6.94540</td>\n      <td>79.8768</td>\n      <td>2.879077</td>\n      <td>858.000000</td>\n      <td>115.000000</td>\n      <td>0.000000</td>\n      <td>317.000000</td>\n      <td>133.31</td>\n    </tr>\n    <tr>\n      <th>17175</th>\n      <td>10.500000</td>\n      <td>46.007301</td>\n      <td>0.027825</td>\n      <td>0.341564</td>\n      <td>0.080153</td>\n      <td>0.371548</td>\n      <td>0.040076</td>\n      <td>0.096268</td>\n      <td>23</td>\n      <td>23</td>\n      <td>6.90257</td>\n      <td>79.9557</td>\n      <td>2.115875</td>\n      <td>262.000000</td>\n      <td>21.000000</td>\n      <td>1.224300</td>\n      <td>23.000000</td>\n      <td>98.57</td>\n    </tr>\n  </tbody>\n</table>\n<p>17176 rows × 18 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_X","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"      additional_fare  mtr_wating_fare_to_waiting_duration  fare_for_time  \\\n0                10.5                             0.012887       0.267557   \n1                10.5                             0.000000       0.440714   \n2                10.5                             0.009564       0.248471   \n3                10.5                             0.000000       0.233818   \n4                10.5                             0.026831       0.153002   \n...               ...                                  ...            ...   \n8571             10.5                             0.057485       0.210688   \n8572             10.5                             0.000000       0.252728   \n8573             10.5                             0.022043       0.214297   \n8574             10.5                             0.056061       0.133736   \n8575             10.5                             0.044868       0.176288   \n\n      meter_waiting_to_duration  fare_for_duration  \\\n0                      0.045455           0.310413   \n1                      0.004707           0.450153   \n2                      0.164304           0.252153   \n3                      0.034632           0.334026   \n4                      0.481572           0.165972   \n...                         ...                ...   \n8571                   0.248984           0.211054   \n8572                   0.058055           0.275653   \n8573                   0.133971           0.261975   \n8574                   0.341646           0.135153   \n8575                   0.406949           0.180649   \n\n      additional_fare_to_duration  additional_fare_to_fare  pick_hour  \\\n0                        0.011364                 0.035027          0   \n1                        0.002471                 0.005460          1   \n2                        0.006765                 0.025958          5   \n3                        0.022727                 0.063706          5   \n4                        0.012899                 0.066468          7   \n...                           ...                      ...        ...   \n8571                     0.006094                 0.026317         21   \n8572                     0.007620                 0.026899         21   \n8573                     0.025120                 0.085165         22   \n8574                     0.006546                 0.040547         22   \n8575                     0.006184                 0.029989         22   \n\n      drop_hour  pick_lat  pick_lon  direct_distance  duration  meter_waiting  \\\n0             0   6.83454   79.8750         6.705702       924             42   \n1             2   6.91168   79.8723        41.558513      4249             20   \n2             5   6.92145   79.8478         5.916678      1552            255   \n3             5   6.77433   79.9416         3.301761       462             16   \n4             7   6.97968   79.9130         2.588542       814            392   \n...         ...       ...       ...              ...       ...            ...   \n8571         21   6.85103   79.9567         3.934272      1723            429   \n8572         22   6.91293   79.9656         7.517433      1378             80   \n8573         22   6.85718   79.9081         2.057225       418             56   \n8574         22   6.91289   79.8846         3.900888      1604            548   \n8575         23   6.91682   79.9192         5.435270      1698            691   \n\n      meter_waiting_fare  meter_waiting_till_pickup     fare  \n0                2.44860                        148   289.27  \n1                0.00000                         91  1912.70  \n2                2.65880                         23   394.00  \n3                0.00000                        198   154.32  \n4               12.36920                         69   147.47  \n...                  ...                        ...      ...  \n8571            24.83332                          3   388.48  \n8572             0.00000                        125   379.85  \n8573             3.28440                         93   112.79  \n8574            31.67440                         17   248.46  \n8575            32.88820                         42   339.63  \n\n[8576 rows x 17 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>additional_fare</th>\n      <th>mtr_wating_fare_to_waiting_duration</th>\n      <th>fare_for_time</th>\n      <th>meter_waiting_to_duration</th>\n      <th>fare_for_duration</th>\n      <th>additional_fare_to_duration</th>\n      <th>additional_fare_to_fare</th>\n      <th>pick_hour</th>\n      <th>drop_hour</th>\n      <th>pick_lat</th>\n      <th>pick_lon</th>\n      <th>direct_distance</th>\n      <th>duration</th>\n      <th>meter_waiting</th>\n      <th>meter_waiting_fare</th>\n      <th>meter_waiting_till_pickup</th>\n      <th>fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10.5</td>\n      <td>0.012887</td>\n      <td>0.267557</td>\n      <td>0.045455</td>\n      <td>0.310413</td>\n      <td>0.011364</td>\n      <td>0.035027</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6.83454</td>\n      <td>79.8750</td>\n      <td>6.705702</td>\n      <td>924</td>\n      <td>42</td>\n      <td>2.44860</td>\n      <td>148</td>\n      <td>289.27</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10.5</td>\n      <td>0.000000</td>\n      <td>0.440714</td>\n      <td>0.004707</td>\n      <td>0.450153</td>\n      <td>0.002471</td>\n      <td>0.005460</td>\n      <td>1</td>\n      <td>2</td>\n      <td>6.91168</td>\n      <td>79.8723</td>\n      <td>41.558513</td>\n      <td>4249</td>\n      <td>20</td>\n      <td>0.00000</td>\n      <td>91</td>\n      <td>1912.70</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10.5</td>\n      <td>0.009564</td>\n      <td>0.248471</td>\n      <td>0.164304</td>\n      <td>0.252153</td>\n      <td>0.006765</td>\n      <td>0.025958</td>\n      <td>5</td>\n      <td>5</td>\n      <td>6.92145</td>\n      <td>79.8478</td>\n      <td>5.916678</td>\n      <td>1552</td>\n      <td>255</td>\n      <td>2.65880</td>\n      <td>23</td>\n      <td>394.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10.5</td>\n      <td>0.000000</td>\n      <td>0.233818</td>\n      <td>0.034632</td>\n      <td>0.334026</td>\n      <td>0.022727</td>\n      <td>0.063706</td>\n      <td>5</td>\n      <td>5</td>\n      <td>6.77433</td>\n      <td>79.9416</td>\n      <td>3.301761</td>\n      <td>462</td>\n      <td>16</td>\n      <td>0.00000</td>\n      <td>198</td>\n      <td>154.32</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10.5</td>\n      <td>0.026831</td>\n      <td>0.153002</td>\n      <td>0.481572</td>\n      <td>0.165972</td>\n      <td>0.012899</td>\n      <td>0.066468</td>\n      <td>7</td>\n      <td>7</td>\n      <td>6.97968</td>\n      <td>79.9130</td>\n      <td>2.588542</td>\n      <td>814</td>\n      <td>392</td>\n      <td>12.36920</td>\n      <td>69</td>\n      <td>147.47</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8571</th>\n      <td>10.5</td>\n      <td>0.057485</td>\n      <td>0.210688</td>\n      <td>0.248984</td>\n      <td>0.211054</td>\n      <td>0.006094</td>\n      <td>0.026317</td>\n      <td>21</td>\n      <td>21</td>\n      <td>6.85103</td>\n      <td>79.9567</td>\n      <td>3.934272</td>\n      <td>1723</td>\n      <td>429</td>\n      <td>24.83332</td>\n      <td>3</td>\n      <td>388.48</td>\n    </tr>\n    <tr>\n      <th>8572</th>\n      <td>10.5</td>\n      <td>0.000000</td>\n      <td>0.252728</td>\n      <td>0.058055</td>\n      <td>0.275653</td>\n      <td>0.007620</td>\n      <td>0.026899</td>\n      <td>21</td>\n      <td>22</td>\n      <td>6.91293</td>\n      <td>79.9656</td>\n      <td>7.517433</td>\n      <td>1378</td>\n      <td>80</td>\n      <td>0.00000</td>\n      <td>125</td>\n      <td>379.85</td>\n    </tr>\n    <tr>\n      <th>8573</th>\n      <td>10.5</td>\n      <td>0.022043</td>\n      <td>0.214297</td>\n      <td>0.133971</td>\n      <td>0.261975</td>\n      <td>0.025120</td>\n      <td>0.085165</td>\n      <td>22</td>\n      <td>22</td>\n      <td>6.85718</td>\n      <td>79.9081</td>\n      <td>2.057225</td>\n      <td>418</td>\n      <td>56</td>\n      <td>3.28440</td>\n      <td>93</td>\n      <td>112.79</td>\n    </tr>\n    <tr>\n      <th>8574</th>\n      <td>10.5</td>\n      <td>0.056061</td>\n      <td>0.133736</td>\n      <td>0.341646</td>\n      <td>0.135153</td>\n      <td>0.006546</td>\n      <td>0.040547</td>\n      <td>22</td>\n      <td>22</td>\n      <td>6.91289</td>\n      <td>79.8846</td>\n      <td>3.900888</td>\n      <td>1604</td>\n      <td>548</td>\n      <td>31.67440</td>\n      <td>17</td>\n      <td>248.46</td>\n    </tr>\n    <tr>\n      <th>8575</th>\n      <td>10.5</td>\n      <td>0.044868</td>\n      <td>0.176288</td>\n      <td>0.406949</td>\n      <td>0.180649</td>\n      <td>0.006184</td>\n      <td>0.029989</td>\n      <td>22</td>\n      <td>23</td>\n      <td>6.91682</td>\n      <td>79.9192</td>\n      <td>5.435270</td>\n      <td>1698</td>\n      <td>691</td>\n      <td>32.88820</td>\n      <td>42</td>\n      <td>339.63</td>\n    </tr>\n  </tbody>\n</table>\n<p>8576 rows × 17 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X, val_X, train_y, val_y = train_test_split(train_X_, train_y_, test_size = 0.2, train_size = 0.8, random_state = 0)","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(model, test_features, test_labels):\n    predictions = model.predict(test_features)\n    mse = mean_squared_error(test_labels, predictions)\n    mae = mean_absolute_error(test_labels, predictions)\n    rmse = np.sqrt(mse)\n    score=cross_val_score(model, test_features, test_labels, cv=10)\n    accuracy = accuracy_score(test_labels, predictions.round())\n    print('Model Performance')\n    print('Accuracy:%f'%accuracy)\n    print(\"Mean cross validation score:%f\"%score.mean())\n    print('Mean Squared Error : %.4f' % mse)\n    print('Root MSE : %.4f' % rmse)","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random forest model"},{"metadata":{"trusted":true},"cell_type":"code","source":"my_random_forest_model = RandomForestRegressor(n_estimators=100, random_state = 0)\nmy_random_forest_model.fit(train_X, train_y)\n\nevaluate(my_random_forest_model, val_X, val_y)\n\npred_classes = my_random_forest_model.predict(val_X)\npredi = []\nfor x in range(len(pred_classes)):\n    predi.append(bool(pred_classes[x]))\n    \npred_classes = np.array(predi)\n\nf1 = f1_score(val_y, pred_classes)\nprint('F1 score: %f' % f1)\n# Multiply by -1 since sklearn calculates *negative* MAE\n#scores = cross_val_score(my_pipeline, X, y, cv=5, scoring='neg_mean_absolute_error')\n#scores = cross_val_score(my_random_forest_model, train_X, train_y.round(), scoring='f1')\n#print(\"MAE scores:\\n\", scores)\n","execution_count":13,"outputs":[{"output_type":"stream","text":"Model Performance\nAccuracy:0.957218\nMean cross validation score:0.504798\nMean Squared Error : 0.0364\nRoot MSE : 0.1909\nF1 score: 0.958141\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Decision tree model"},{"metadata":{"trusted":true},"cell_type":"code","source":"my_decision_tree_model = DecisionTreeRegressor(min_samples_split=100,\n        max_features=\"auto\", random_state=50, \n        max_depth=100)\nmy_decision_tree_model.fit(train_X, train_y)\n\nevaluate(my_decision_tree_model, val_X, val_y)\n\npred_classes = my_decision_tree_model.predict(val_X)\npredi = []\nfor x in range(len(pred_classes)):\n    predi.append(bool(pred_classes[x]))\n    \npred_classes = np.array(predi)\n\nf1 = f1_score(val_y, pred_classes)\nprint('F1 score: %f' % f1)","execution_count":26,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Input contains NaN, infinity or a value too large for dtype('float32').","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-4f45693106b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         max_depth=100)\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmy_decision_tree_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_decision_tree_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 578\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."]}]},{"metadata":{},"cell_type":"markdown","source":"ADA Boost model"},{"metadata":{"trusted":true},"cell_type":"code","source":"Ada_boost_model = AdaBoostRegressor()\nAda_boost_model.fit(train_X, train_y)\n\nevaluate(Ada_boost_model, val_X, val_y)\n\npred_classes = Ada_boost_model.predict(val_X)\npredi = []\nfor x in range(len(pred_classes)):\n    predi.append(bool(pred_classes[x]))\n    \npred_classes = np.array(predi)\n\nf1 = f1_score(val_y, pred_classes)\nprint('F1 score: %f' % f1)","execution_count":14,"outputs":[{"output_type":"stream","text":"Model Performance\nAccuracy:0.939464\nMean cross validation score:0.186050\nMean Squared Error : 0.0826\nRoot MSE : 0.2874\nF1 score: 0.951000\n","name":"stdout"}]},{"metadata":{},"cell_type":"raw","source":"Grid Search model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nclf = LogisticRegression(C=1, penalty='l1', solver='liblinear')\nparam_grid = {'C':[0.001,.009,0.01,.09,1,5,10,25]}\n'''{\n    'n_estimators' : [10, 200],\n    'max_features' : ['auto', 'sqrt', 'log2', 0.5]\n}'''\ngs_model = GridSearchCV(clf, param_grid = param_grid, scoring = 'recall')\ngs_model.fit(train_X, train_y)\n\npredictions = gs_model.predict(val_X)\naccuracy = accuracy_score(val_y, predictions.round())\nprint('Accuracy:%f'%accuracy)","execution_count":15,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n","name":"stderr"},{"output_type":"stream","text":"Accuracy:0.911816\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n#def create_baseline():\n'''\nmodel = Sequential()\nmodel.add(Dense(7, activation='relu'))\nmodel.add(Dense(7, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(7, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(7, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(7, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(7, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(7, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(7, activation='relu'))\n#model.add(Dropout(0.4))\nmodel.add(Dense(1, activation='softmax'))\n#model.add(Dense(1, activation='sigmoid'))\n#model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\nmodel.compile(loss='mse', optimizer='Adam', metrics=[tf.keras.metrics.MeanSquaredError(),tf.keras.metrics.Accuracy()])\n#tf.keras.metrics.BinaryAccuracy()\n#adam,sgd\n#return model\n'''\nfrom keras.layers import BatchNormalization\nmodel = Sequential()\nmodel.add(Dense(15))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(BatchNormalization())\nmodel.add(Dense(256,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(128,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(64,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(32,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(16,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(8,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(1,activation='softmax'))\n\nmodel.compile(optimizer='adam',loss='mse', metrics=['accuracy',f1_m])\n#model.compile(loss=keras.losses.categorical_crossentropy,optimizer='adam',metrics=['accuracy'])\n\n#estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=10, verbose=0)\n#kfold = StratifiedKFold(n_splits=10, shuffle=True)\n#results = cross_val_score(estimator, train_X, train_y, cv=kfold)\n#print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\nmodel.fit(train_X_.values, train_y_.values,\n          batch_size=20,\n          epochs=5,\n          validation_split = 0.2,\n          verbose = 1,\n          shuffle=True)\n\n#evaluate(model, val_X, val_y)\npred_classes = model.predict(val_X)\npredi = []\nfor x in range(len(pred_classes)):\n    predi.append(bool(pred_classes[x]))\n    \npred_classes = np.array(predi)\n\nf1 = f1_score(val_y, pred_classes)\nprint('F1 score: %f' % f1)","execution_count":16,"outputs":[{"output_type":"stream","text":"Train on 13740 samples, validate on 3436 samples\nEpoch 1/5\n13740/13740 [==============================] - 8s 598us/step - loss: 0.0999 - accuracy: 0.9001 - f1_m: 0.9461 - val_loss: 0.0896 - val_accuracy: 0.9104 - val_f1_m: 0.9517\nEpoch 2/5\n13740/13740 [==============================] - 5s 370us/step - loss: 0.0999 - accuracy: 0.9001 - f1_m: 0.9459 - val_loss: 0.0896 - val_accuracy: 0.9104 - val_f1_m: 0.9517\nEpoch 3/5\n13740/13740 [==============================] - 5s 369us/step - loss: 0.0999 - accuracy: 0.9001 - f1_m: 0.9460 - val_loss: 0.0896 - val_accuracy: 0.9104 - val_f1_m: 0.9517\nEpoch 4/5\n13740/13740 [==============================] - 5s 386us/step - loss: 0.0999 - accuracy: 0.9001 - f1_m: 0.9462 - val_loss: 0.0896 - val_accuracy: 0.9104 - val_f1_m: 0.9517\nEpoch 5/5\n13740/13740 [==============================] - 5s 382us/step - loss: 0.0999 - accuracy: 0.9001 - f1_m: 0.9461 - val_loss: 0.0896 - val_accuracy: 0.9104 - val_f1_m: 0.9517\nF1 score: 0.951000\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg_model = xgboost.XGBClassifier(base_score=0.1, booster= None, colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\n              gamma=0.4, gpu_id=0, importance_type='gain',\n              interaction_constraints=None, learning_rate=0.01,\n              max_delta_step=0, max_depth=80, min_child_weight=7, missing=None,\n              monotone_constraints=None, n_estimators=1000, n_jobs=6, nthread=6,\n              num_parallel_tree=1, objective='binary:logistic', random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, silent=False,\n              subsample=0.8,tree_method='hist', validate_parameters=False,\n              verbosity=1)\n#xg_model = xgboost.XGBClassifier()\n#base_score 0.5 -> 0.1\n#score=cross_val_score(xg_model, train_X, train_y, cv=10)\nxg_model.fit(train_X, train_y)\n","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"XGBClassifier(base_score=0.1, booster=None, colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\n              gamma=0.4, gpu_id=0, importance_type='gain',\n              interaction_constraints=None, learning_rate=0.01,\n              max_delta_step=0, max_depth=80, min_child_weight=7, missing=nan,\n              monotone_constraints=None, n_estimators=1000, n_jobs=6, nthread=6,\n              num_parallel_tree=1, objective='binary:logistic', random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, silent=False,\n              subsample=0.8, tree_method='hist', validate_parameters=False,\n              verbosity=1)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def xg_evaluate(model, test_features, test_labels):\n    predictions = model.predict(test_features)\n    #mse = mean_squared_error(test_labels, predictions)\n    #mae = mean_absolute_error(test_labels, predictions)\n    #rmse = np.sqrt(mse)\n    #score=cross_val_score(model, test_features, test_labels, cv=10)\n    accuracy = accuracy_score(test_labels, predictions.round())\n    #print('Model Performance')\n    print('Accuracy:%f'%accuracy)\n    #print(\"Mean cross validation score:%f\"%score.mean())\n    #print('Mean Squared Error : %.4f' % mse)\n    #print('Root MSE : %.4f' % rmse)\nxg_evaluate(xg_model, val_X, val_y)\npred_classes = xg_model.predict(val_X)\npredi = []\nfor x in range(len(pred_classes)):\n    predi.append(bool(pred_classes[x]))\n    \npred_classes = np.array(predi)\n\nf1 = f1_score(val_y, pred_classes)\nprint('F1 score: %f' % f1)","execution_count":19,"outputs":[{"output_type":"stream","text":"Accuracy:0.956054\nF1 score: 0.975982\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn_classifier = KNeighborsClassifier(n_neighbors=7)\nknn_classifier.fit(train_X, train_y)\n\ndef knn_evaluate(model, test_features, test_labels):\n    predictions = model.predict(test_features)\n    #mse = mean_squared_error(test_labels, predictions)\n    #mae = mean_absolute_error(test_labels, predictions)\n    #rmse = np.sqrt(mse)\n    #score=cross_val_score(model, test_features, test_labels, cv=10)\n    accuracy = accuracy_score(test_labels, predictions.round())\n    #print('Model Performance')\n    print('Accuracy:%f'%accuracy)\n    #print(\"Mean cross validation score:%f\"%score.mean())\n    #print('Mean Squared Error : %.4f' % mse)\n    #print('Root MSE : %.4f' % rmse)\nknn_evaluate(knn_classifier, val_X, val_y)\n\npred_classes = knn_classifier.predict(val_X)\npredi = []\nfor x in range(len(pred_classes)):\n    predi.append(bool(pred_classes[x]))\n    \npred_classes = np.array(predi)\n\nf1 = f1_score(val_y, pred_classes)\nprint('F1 score: %f' % f1)","execution_count":20,"outputs":[{"output_type":"stream","text":"Accuracy:0.946740\nF1 score: 0.971140\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_rf = my_random_forest_model.predict(test_X)\npredicted_dt = my_decision_tree_model.predict(test_X)\npredicted_ad = Ada_boost_model.predict(test_X)\npredicted_xg = xg_model.predict(test_X)\npredicted_NN = model.predict(test_X)\npredicted_KNN = knn_classifier.predict(test_X)\n\npred_KNN = []\nfor x in range(len(predicted_KNN)):\n    pred_KNN.append(bool(predicted_KNN[x]))\n\npredicted_KNN = np.array(pred_KNN)\n\npred_NN = []\nfor x in range(len(predicted_NN)):\n    pred_NN.append(bool(predicted_NN[x]))\n\npredicted_NN = np.array(pred_NN)\n    \npred_rf = []\nfor x in range(len(predicted_rf)):\n    pred_rf.append(bool(predicted_rf[x]))\n    \npredicted_rf = np.array(pred_rf)\n    \npred_dt = []\nfor x in range(len(predicted_dt)):\n    pred_dt.append(bool(predicted_dt[x]))\n\npredicted_dt = np.array(pred_dt)\n\npred_ad = []\nfor x in range(len(predicted_ad)):\n    pred_ad.append(bool(predicted_ad[x]))\n\npredicted_ad = np.array(pred_ad)\n\npred_xg = []\nfor x in range(len(predicted_xg)):\n    pred_xg.append(bool(predicted_xg[x]))\n    \npredicted_xg = np.array(pred_xg)\n\noutput_rf = pd.DataFrame({'tripid': test.tripid,\n                       'prediction': predicted_rf})\n\noutput_dt = pd.DataFrame({'tripid': test.tripid,\n                       'prediction': predicted_dt})\n\noutput_adb = pd.DataFrame({'tripid': test.tripid,\n                       'prediction': predicted_dt})\n\noutput_xg = pd.DataFrame({'tripid': test.tripid,\n                       'prediction': predicted_xg})\n\noutput_NN = pd.DataFrame({'tripid': test.tripid,\n                       'prediction': predicted_NN})\n\noutput_KNN = pd.DataFrame({'tripid': test.tripid,\n                       'prediction': predicted_KNN})\n\noutput_rf_path = \"submission_rf.csv\"\noutput_dt_path = \"submission_dt.csv\"\noutput_adb_path = \"submission_adb.csv\"\noutput_xg_path = \"submission_xg.csv\"\noutput_NN_path = \"submission_nn.csv\"\noutput_KNN_path = \"submission_knn.csv\"\n\noutput_rf.to_csv(output_rf_path, index=False)\noutput_dt.to_csv(output_dt_path, index=False)\noutput_adb.to_csv(output_adb_path, index = False)\noutput_xg.to_csv(output_xg_path, index = False)\noutput_NN.to_csv(output_NN_path, index = False)\noutput_KNN.to_csv(output_KNN_path, index = False)","execution_count":21,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}